{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9725f1ba",
   "metadata": {},
   "source": [
    "# SentinalX - Hybrid Fraud Detection Model Training\n",
    "## Interactive Notebook for Training & Debugging\n",
    "\n",
    "This notebook breaks down the training pipeline into separate executable blocks for easy debugging and experimentation.\n",
    "\n",
    "**Pipeline Overview:**\n",
    "1. üì¶ Imports & Setup\n",
    "2. üìä Load & Explore Data\n",
    "3. üîç Test Hard Rule Filter\n",
    "4. ‚öôÔ∏è Feature Preparation\n",
    "5. ü§ñ Initialize Model\n",
    "6. üöÄ Train Isolation Forest\n",
    "7. üîÆ Test Predictions\n",
    "8. üìà Evaluate Metrics\n",
    "9. üíæ Save Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c95c213",
   "metadata": {},
   "source": [
    "## 1. üì¶ Import Required Libraries\n",
    "\n",
    "Import all necessary libraries for data processing, machine learning, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "886f55fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n",
      "   Pandas version: 3.0.0\n",
      "   Numpy version: 2.4.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"   Pandas version: {pd.__version__}\")\n",
    "print(f\"   Numpy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbd9359",
   "metadata": {},
   "source": [
    "## 2. üìä Load and Explore Training Data\n",
    "\n",
    "Load the training dataset and display basic statistics to understand the data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f991dd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading training data...\n",
      "‚úÖ Loaded 13,000 training samples\n",
      "\n",
      "üìä Dataset Overview:\n",
      "   Shape: (13000, 13)\n",
      "   Features: ['phoneNumber', 'avgDuration', 'callFrequency', 'uniqueContacts', 'avgCallDistance', 'circleDiversity', 'label', 'userType', 'call_intensity', 'distance_per_call', 'contact_circle_ratio', 'high_freq_long_distance', 'delivery_pattern']\n",
      "\n",
      "üìä Label Distribution:\n",
      "   LEGITIMATE: 10,238 (78.8%)\n",
      "   FRAUD: 2,762 (21.2%)\n",
      "\n",
      "üìä User Type Distribution:\n",
      "userType\n",
      "BUSINESS_USER             3000\n",
      "DELIVERY_PARTNER          3000\n",
      "DIGITAL_ARREST_BOT        1500\n",
      "LOW_VOLUME_SCAMMER         262\n",
      "REGULAR_USER              4000\n",
      "TRADITIONAL_SCAMMER       1000\n",
      "TRAVELING_PROFESSIONAL     238\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìã First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phoneNumber</th>\n",
       "      <th>avgDuration</th>\n",
       "      <th>callFrequency</th>\n",
       "      <th>uniqueContacts</th>\n",
       "      <th>avgCallDistance</th>\n",
       "      <th>circleDiversity</th>\n",
       "      <th>label</th>\n",
       "      <th>userType</th>\n",
       "      <th>call_intensity</th>\n",
       "      <th>distance_per_call</th>\n",
       "      <th>contact_circle_ratio</th>\n",
       "      <th>high_freq_long_distance</th>\n",
       "      <th>delivery_pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>916698198780</td>\n",
       "      <td>4.168521</td>\n",
       "      <td>84</td>\n",
       "      <td>78</td>\n",
       "      <td>5.924908</td>\n",
       "      <td>1</td>\n",
       "      <td>LEGITIMATE</td>\n",
       "      <td>DELIVERY_PARTNER</td>\n",
       "      <td>16.252232</td>\n",
       "      <td>0.069705</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>917859421937</td>\n",
       "      <td>215.629137</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>174.310282</td>\n",
       "      <td>1</td>\n",
       "      <td>LEGITIMATE</td>\n",
       "      <td>REGULAR_USER</td>\n",
       "      <td>0.087707</td>\n",
       "      <td>8.715514</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>918673614047</td>\n",
       "      <td>73.762206</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>559.378040</td>\n",
       "      <td>1</td>\n",
       "      <td>LEGITIMATE</td>\n",
       "      <td>REGULAR_USER</td>\n",
       "      <td>0.347769</td>\n",
       "      <td>20.717705</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>918971147766</td>\n",
       "      <td>54.947743</td>\n",
       "      <td>62</td>\n",
       "      <td>111</td>\n",
       "      <td>1010.016874</td>\n",
       "      <td>4</td>\n",
       "      <td>FRAUD</td>\n",
       "      <td>TRADITIONAL_SCAMMER</td>\n",
       "      <td>1.108177</td>\n",
       "      <td>16.032014</td>\n",
       "      <td>22.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917277642649</td>\n",
       "      <td>25.195583</td>\n",
       "      <td>44</td>\n",
       "      <td>64</td>\n",
       "      <td>1613.389214</td>\n",
       "      <td>3</td>\n",
       "      <td>FRAUD</td>\n",
       "      <td>TRADITIONAL_SCAMMER</td>\n",
       "      <td>1.679672</td>\n",
       "      <td>35.853094</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    phoneNumber  avgDuration  callFrequency  uniqueContacts  avgCallDistance  \\\n",
       "0  916698198780     4.168521             84              78         5.924908   \n",
       "1  917859421937   215.629137             19              15       174.310282   \n",
       "2  918673614047    73.762206             26              39       559.378040   \n",
       "3  918971147766    54.947743             62             111      1010.016874   \n",
       "4  917277642649    25.195583             44              64      1613.389214   \n",
       "\n",
       "   circleDiversity       label             userType  call_intensity  \\\n",
       "0                1  LEGITIMATE     DELIVERY_PARTNER       16.252232   \n",
       "1                1  LEGITIMATE         REGULAR_USER        0.087707   \n",
       "2                1  LEGITIMATE         REGULAR_USER        0.347769   \n",
       "3                4       FRAUD  TRADITIONAL_SCAMMER        1.108177   \n",
       "4                3       FRAUD  TRADITIONAL_SCAMMER        1.679672   \n",
       "\n",
       "   distance_per_call  contact_circle_ratio  high_freq_long_distance  \\\n",
       "0           0.069705                  39.0                        0   \n",
       "1           8.715514                   7.5                        0   \n",
       "2          20.717705                  19.5                        0   \n",
       "3          16.032014                  22.2                        1   \n",
       "4          35.853094                  16.0                        0   \n",
       "\n",
       "   delivery_pattern  \n",
       "0                 1  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data\n",
    "print(\"üìÇ Loading training data...\")\n",
    "train_df = pd.read_csv('Data/training_dataset.csv')\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(train_df):,} training samples\\n\")\n",
    "\n",
    "# Display dataset info\n",
    "print(\"üìä Dataset Overview:\")\n",
    "print(f\"   Shape: {train_df.shape}\")\n",
    "print(f\"   Features: {train_df.columns.tolist()}\")\n",
    "\n",
    "print(\"\\nüìä Label Distribution:\")\n",
    "label_counts = train_df['label'].value_counts()\n",
    "for label, count in label_counts.items():\n",
    "    pct = count / len(train_df) * 100\n",
    "    print(f\"   {label}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "print(\"\\nüìä User Type Distribution:\")\n",
    "print(train_df['userType'].value_counts().sort_index())\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nüìã First 5 rows:\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63980ef1",
   "metadata": {},
   "source": [
    "## 3. üîç Test Hard Rule Filter (Stage 1)\n",
    "\n",
    "Test the hard rule logic that protects delivery partners:\n",
    "- **Rule**: `callFrequency > 50 AND avgCallDistance < 10`\n",
    "- **Goal**: Zero false positives for delivery partners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12c7eb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã STAGE 1: Hard Rule Filter Results\n",
      "============================================================\n",
      "‚úì Hard rule protected: 2,554 records\n",
      "‚úì Remaining for ML: 10,446 records\n",
      "‚úì Hard rule accuracy: 100.00%\n",
      "‚úì Fraud cases in safe zone: 0\n",
      "\n",
      "üìä User types protected by hard rule:\n",
      "userType\n",
      "DELIVERY_PARTNER    2554\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìä Remaining user types for ML evaluation:\n",
      "userType\n",
      "REGULAR_USER              4000\n",
      "BUSINESS_USER             3000\n",
      "DIGITAL_ARREST_BOT        1500\n",
      "TRADITIONAL_SCAMMER       1000\n",
      "DELIVERY_PARTNER           446\n",
      "LOW_VOLUME_SCAMMER         262\n",
      "TRAVELING_PROFESSIONAL     238\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Apply hard rule filter\n",
    "hard_rule_mask = (train_df['callFrequency'] > 50) & (train_df['avgCallDistance'] < 10)\n",
    "\n",
    "rule_safe = train_df[hard_rule_mask].copy()\n",
    "remaining = train_df[~hard_rule_mask].copy()\n",
    "\n",
    "print(\"üìã STAGE 1: Hard Rule Filter Results\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"‚úì Hard rule protected: {len(rule_safe):,} records\")\n",
    "print(f\"‚úì Remaining for ML: {len(remaining):,} records\")\n",
    "\n",
    "# Check accuracy of hard rule\n",
    "if len(rule_safe) > 0:\n",
    "    rule_accuracy = (rule_safe['label'] == 'LEGITIMATE').sum() / len(rule_safe)\n",
    "    print(f\"‚úì Hard rule accuracy: {rule_accuracy*100:.2f}%\")\n",
    "    \n",
    "    # Check if any fraud slipped through\n",
    "    fraud_in_safe = (rule_safe['label'] == 'FRAUD').sum()\n",
    "    print(f\"‚úì Fraud cases in safe zone: {fraud_in_safe}\")\n",
    "    \n",
    "    # Display user types protected by hard rule\n",
    "    print(f\"\\nüìä User types protected by hard rule:\")\n",
    "    print(rule_safe['userType'].value_counts())\n",
    "\n",
    "print(f\"\\nüìä Remaining user types for ML evaluation:\")\n",
    "print(remaining['userType'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d15c182",
   "metadata": {},
   "source": [
    "## 4. ‚öôÔ∏è Configure Features\n",
    "\n",
    "Define the feature columns that will be used for the Isolation Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86b97269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Feature Configuration\n",
      "============================================================\n",
      "Total features: 9\n",
      "\n",
      "Features:\n",
      "  1. avgDuration\n",
      "  2. callFrequency\n",
      "  3. uniqueContacts\n",
      "  4. avgCallDistance\n",
      "  5. circleDiversity\n",
      "  6. call_intensity\n",
      "  7. distance_per_call\n",
      "  8. contact_circle_ratio\n",
      "  9. high_freq_long_distance\n",
      "\n",
      "‚úì Checking feature availability in dataset...\n",
      "‚úÖ All 9 features available!\n",
      "\n",
      "üìä Feature Statistics (for ML evaluation set):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avgDuration</th>\n",
       "      <th>callFrequency</th>\n",
       "      <th>uniqueContacts</th>\n",
       "      <th>avgCallDistance</th>\n",
       "      <th>circleDiversity</th>\n",
       "      <th>call_intensity</th>\n",
       "      <th>distance_per_call</th>\n",
       "      <th>contact_circle_ratio</th>\n",
       "      <th>high_freq_long_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10446.000000</td>\n",
       "      <td>10446.000000</td>\n",
       "      <td>10446.000000</td>\n",
       "      <td>10446.000000</td>\n",
       "      <td>10446.000000</td>\n",
       "      <td>10446.000000</td>\n",
       "      <td>10446.000000</td>\n",
       "      <td>10446.000000</td>\n",
       "      <td>10446.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>127.899011</td>\n",
       "      <td>37.891346</td>\n",
       "      <td>64.112579</td>\n",
       "      <td>704.572528</td>\n",
       "      <td>2.940551</td>\n",
       "      <td>2.406145</td>\n",
       "      <td>19.232193</td>\n",
       "      <td>15.733499</td>\n",
       "      <td>0.180069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>114.933723</td>\n",
       "      <td>25.331774</td>\n",
       "      <td>50.973598</td>\n",
       "      <td>674.492148</td>\n",
       "      <td>2.051610</td>\n",
       "      <td>5.009234</td>\n",
       "      <td>14.209815</td>\n",
       "      <td>7.680529</td>\n",
       "      <td>0.384263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.010070</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.511443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011884</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.413501</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>228.378355</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.090071</td>\n",
       "      <td>9.246434</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>93.396610</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>470.317602</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.314689</td>\n",
       "      <td>16.930586</td>\n",
       "      <td>14.666667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>181.985217</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>985.404791</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.258456</td>\n",
       "      <td>26.035091</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>419.877452</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>2798.549468</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>37.065292</td>\n",
       "      <td>99.714048</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        avgDuration  callFrequency  uniqueContacts  avgCallDistance  \\\n",
       "count  10446.000000   10446.000000    10446.000000     10446.000000   \n",
       "mean     127.899011      37.891346       64.112579       704.572528   \n",
       "std      114.933723      25.331774       50.973598       674.492148   \n",
       "min        2.010070       5.000000        8.000000         0.511443   \n",
       "25%       33.413501      20.000000       31.000000       228.378355   \n",
       "50%       93.396610      33.000000       50.000000       470.317602   \n",
       "75%      181.985217      48.000000       77.000000       985.404791   \n",
       "max      419.877452     119.000000      249.000000      2798.549468   \n",
       "\n",
       "       circleDiversity  call_intensity  distance_per_call  \\\n",
       "count     10446.000000    10446.000000       10446.000000   \n",
       "mean          2.940551        2.406145          19.232193   \n",
       "std           2.051610        5.009234          14.209815   \n",
       "min           1.000000        0.011884           0.010709   \n",
       "25%           2.000000        0.090071           9.246434   \n",
       "50%           2.000000        0.314689          16.930586   \n",
       "75%           3.000000        1.258456          26.035091   \n",
       "max           9.000000       37.065292          99.714048   \n",
       "\n",
       "       contact_circle_ratio  high_freq_long_distance  \n",
       "count          10446.000000             10446.000000  \n",
       "mean              15.733499                 0.180069  \n",
       "std                7.680529                 0.384263  \n",
       "min                2.666667                 0.000000  \n",
       "25%               10.333333                 0.000000  \n",
       "50%               14.666667                 0.000000  \n",
       "75%               20.000000                 0.000000  \n",
       "max               47.000000                 1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define feature columns for the model\n",
    "feature_columns = [\n",
    "    'avgDuration',           # Base feature\n",
    "    'callFrequency',         # Base feature\n",
    "    'uniqueContacts',        # Base feature\n",
    "    'avgCallDistance',       # Base feature\n",
    "    'circleDiversity',       # Base feature\n",
    "    'call_intensity',        # Engineered feature\n",
    "    'distance_per_call',     # Engineered feature\n",
    "    'contact_circle_ratio',  # Engineered feature\n",
    "    'high_freq_long_distance'# Engineered feature (binary)\n",
    "]\n",
    "\n",
    "print(\"üìã Feature Configuration\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total features: {len(feature_columns)}\")\n",
    "print(\"\\nFeatures:\")\n",
    "for i, feat in enumerate(feature_columns, 1):\n",
    "    print(f\"  {i}. {feat}\")\n",
    "\n",
    "# Check if all features exist in the dataset\n",
    "print(\"\\n‚úì Checking feature availability in dataset...\")\n",
    "missing_features = [f for f in feature_columns if f not in remaining.columns]\n",
    "if missing_features:\n",
    "    print(f\"‚ùå Missing features: {missing_features}\")\n",
    "else:\n",
    "    print(f\"‚úÖ All {len(feature_columns)} features available!\")\n",
    "    \n",
    "# Display feature statistics\n",
    "print(\"\\nüìä Feature Statistics (for ML evaluation set):\")\n",
    "remaining[feature_columns].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7ddfcf",
   "metadata": {},
   "source": [
    "## 5. üîÑ Prepare and Scale Features\n",
    "\n",
    "Extract features from the remaining dataset and apply StandardScaler normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed8e8c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Feature Preparation\n",
      "============================================================\n",
      "‚úì Training samples: 10,446\n",
      "‚úì Features: 9\n",
      "‚úì Target distribution: {0: 7684, 1: 2762}\n",
      "\n",
      "‚öôÔ∏è Fitting StandardScaler...\n",
      "‚úÖ Feature scaling complete!\n",
      "\n",
      "üìä Scaled feature statistics:\n",
      "   Mean (should be ~0): -0.000000\n",
      "   Std (should be ~1): 1.000000\n",
      "   Shape: (10446, 9)\n",
      "\n",
      "üìä Example: First sample comparison\n",
      "\n",
      "Original values:\n",
      "avgDuration                215.629137\n",
      "callFrequency               19.000000\n",
      "uniqueContacts              15.000000\n",
      "avgCallDistance            174.310282\n",
      "circleDiversity              1.000000\n",
      "call_intensity               0.087707\n",
      "distance_per_call            8.715514\n",
      "contact_circle_ratio         7.500000\n",
      "high_freq_long_distance      0.000000\n",
      "Name: 1, dtype: float64\n",
      "\n",
      "Scaled values:\n",
      "avgDuration                0.763347\n",
      "callFrequency             -0.745793\n",
      "uniqueContacts            -0.963537\n",
      "avgCallDistance           -0.786203\n",
      "circleDiversity           -0.945913\n",
      "call_intensity            -0.462855\n",
      "distance_per_call         -0.740135\n",
      "contact_circle_ratio      -1.072048\n",
      "high_freq_long_distance   -0.468631\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Prepare features for training\n",
    "X_train = remaining[feature_columns].copy()\n",
    "y_train = (remaining['label'] == 'FRAUD').astype(int)\n",
    "\n",
    "# Handle any missing values\n",
    "X_train = X_train.fillna(X_train.mean())\n",
    "\n",
    "print(\"‚öôÔ∏è Feature Preparation\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"‚úì Training samples: {len(X_train):,}\")\n",
    "print(f\"‚úì Features: {X_train.shape[1]}\")\n",
    "print(f\"‚úì Target distribution: {y_train.value_counts().to_dict()}\")\n",
    "\n",
    "# Initialize and fit scaler\n",
    "print(\"\\n‚öôÔ∏è Fitting StandardScaler...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "print(f\"‚úÖ Feature scaling complete!\")\n",
    "print(f\"\\nüìä Scaled feature statistics:\")\n",
    "print(f\"   Mean (should be ~0): {X_train_scaled.mean():.6f}\")\n",
    "print(f\"   Std (should be ~1): {X_train_scaled.std():.6f}\")\n",
    "print(f\"   Shape: {X_train_scaled.shape}\")\n",
    "\n",
    "# Display original vs scaled comparison for first sample\n",
    "print(f\"\\nüìä Example: First sample comparison\")\n",
    "print(\"\\nOriginal values:\")\n",
    "print(X_train.iloc[0])\n",
    "print(\"\\nScaled values:\")\n",
    "print(pd.Series(X_train_scaled[0], index=feature_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8dd3cc",
   "metadata": {},
   "source": [
    "## 6. ü§ñ Initialize Isolation Forest Model (Stage 2)\n",
    "\n",
    "Configure the Isolation Forest with optimal parameters for fraud detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d86d34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Isolation Forest Configuration\n",
      "============================================================\n",
      "  ‚Ä¢ n_estimators: 200 (number of trees)\n",
      "  ‚Ä¢ contamination: 0.25 (expected fraud rate)\n",
      "  ‚Ä¢ max_samples: 512 (samples per tree)\n",
      "  ‚Ä¢ random_state: 42\n",
      "  ‚Ä¢ n_jobs: -1 (use all CPU cores)\n",
      "\n",
      "‚úÖ Model initialized!\n"
     ]
    }
   ],
   "source": [
    "# Initialize Isolation Forest with optimized parameters\n",
    "n_estimators = 200      # Number of trees\n",
    "contamination = 0.25     # Expected fraud rate (30%)\n",
    "max_samples = 512       # Samples per tree (speed optimization)\n",
    "random_state = 42       # For reproducibility\n",
    "\n",
    "isolation_forest = IsolationForest(\n",
    "    n_estimators=n_estimators,\n",
    "    contamination=contamination,\n",
    "    max_samples=max_samples,\n",
    "    random_state=random_state,\n",
    "    n_jobs=-1,  # Use all CPU cores\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(\"ü§ñ Isolation Forest Configuration\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  ‚Ä¢ n_estimators: {n_estimators} (number of trees)\")\n",
    "print(f\"  ‚Ä¢ contamination: {contamination} (expected fraud rate)\")\n",
    "print(f\"  ‚Ä¢ max_samples: {max_samples} (samples per tree)\")\n",
    "print(f\"  ‚Ä¢ random_state: {random_state}\")\n",
    "print(f\"  ‚Ä¢ n_jobs: -1 (use all CPU cores)\")\n",
    "print(f\"\\n‚úÖ Model initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f686f8",
   "metadata": {},
   "source": [
    "## 7. üöÄ Train the Isolation Forest\n",
    "\n",
    "Train the model on the scaled feature data. This may take 10-30 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16a3e36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üå≤ Training Isolation Forest...\n",
      "============================================================\n",
      "‚úÖ Training complete!\n",
      "   Training time: 0.37 seconds\n",
      "   Samples used: 10,446\n",
      "   Model ready for predictions!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print(\"üå≤ Training Isolation Forest...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Track training time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "isolation_forest.fit(X_train_scaled)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"‚úÖ Training complete!\")\n",
    "print(f\"   Training time: {training_time:.2f} seconds\")\n",
    "print(f\"   Samples used: {len(X_train_scaled):,}\")\n",
    "print(f\"   Model ready for predictions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ac0a7d",
   "metadata": {},
   "source": [
    "## 8. üîÆ Make Predictions on Training Set\n",
    "\n",
    "Apply the hybrid system (hard rule + ML) to make predictions on the entire training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee564a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÆ Making predictions...\n",
      "============================================================\n",
      "‚úÖ Predictions complete!\n",
      "\n",
      "üìä Prediction Distribution:\n",
      "prediction\n",
      "LEGITIMATE    10388\n",
      "FRAUD          2612\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìä Detection Stage Distribution:\n",
      "detection_stage\n",
      "ML_ISOLATION_FOREST    10446\n",
      "RULE_BASED              2554\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìã Example predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phoneNumber</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>detection_stage</th>\n",
       "      <th>anomaly_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>916698198780</td>\n",
       "      <td>LEGITIMATE</td>\n",
       "      <td>LEGITIMATE</td>\n",
       "      <td>RULE_BASED</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>917859421937</td>\n",
       "      <td>LEGITIMATE</td>\n",
       "      <td>LEGITIMATE</td>\n",
       "      <td>ML_ISOLATION_FOREST</td>\n",
       "      <td>0.075877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>918673614047</td>\n",
       "      <td>LEGITIMATE</td>\n",
       "      <td>LEGITIMATE</td>\n",
       "      <td>ML_ISOLATION_FOREST</td>\n",
       "      <td>0.072277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>918971147766</td>\n",
       "      <td>FRAUD</td>\n",
       "      <td>FRAUD</td>\n",
       "      <td>ML_ISOLATION_FOREST</td>\n",
       "      <td>-0.033204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917277642649</td>\n",
       "      <td>FRAUD</td>\n",
       "      <td>LEGITIMATE</td>\n",
       "      <td>ML_ISOLATION_FOREST</td>\n",
       "      <td>0.022571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>919064934039</td>\n",
       "      <td>LEGITIMATE</td>\n",
       "      <td>LEGITIMATE</td>\n",
       "      <td>RULE_BASED</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>919189098308</td>\n",
       "      <td>LEGITIMATE</td>\n",
       "      <td>LEGITIMATE</td>\n",
       "      <td>ML_ISOLATION_FOREST</td>\n",
       "      <td>0.098215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>919588990580</td>\n",
       "      <td>LEGITIMATE</td>\n",
       "      <td>LEGITIMATE</td>\n",
       "      <td>ML_ISOLATION_FOREST</td>\n",
       "      <td>0.072636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>917490230771</td>\n",
       "      <td>LEGITIMATE</td>\n",
       "      <td>LEGITIMATE</td>\n",
       "      <td>ML_ISOLATION_FOREST</td>\n",
       "      <td>0.075809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>917321115495</td>\n",
       "      <td>LEGITIMATE</td>\n",
       "      <td>LEGITIMATE</td>\n",
       "      <td>ML_ISOLATION_FOREST</td>\n",
       "      <td>0.085086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    phoneNumber       label  prediction      detection_stage  anomaly_score\n",
       "0  916698198780  LEGITIMATE  LEGITIMATE           RULE_BASED       0.000000\n",
       "1  917859421937  LEGITIMATE  LEGITIMATE  ML_ISOLATION_FOREST       0.075877\n",
       "2  918673614047  LEGITIMATE  LEGITIMATE  ML_ISOLATION_FOREST       0.072277\n",
       "3  918971147766       FRAUD       FRAUD  ML_ISOLATION_FOREST      -0.033204\n",
       "4  917277642649       FRAUD  LEGITIMATE  ML_ISOLATION_FOREST       0.022571\n",
       "5  919064934039  LEGITIMATE  LEGITIMATE           RULE_BASED       0.000000\n",
       "6  919189098308  LEGITIMATE  LEGITIMATE  ML_ISOLATION_FOREST       0.098215\n",
       "7  919588990580  LEGITIMATE  LEGITIMATE  ML_ISOLATION_FOREST       0.072636\n",
       "8  917490230771  LEGITIMATE  LEGITIMATE  ML_ISOLATION_FOREST       0.075809\n",
       "9  917321115495  LEGITIMATE  LEGITIMATE  ML_ISOLATION_FOREST       0.085086"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the remaining dataset (ML predictions)\n",
    "print(\"üîÆ Making predictions...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Predict on the remaining dataset\n",
    "ml_predictions = isolation_forest.predict(X_train_scaled)\n",
    "anomaly_scores = isolation_forest.decision_function(X_train_scaled)\n",
    "\n",
    "# Convert predictions (-1 = fraud, 1 = legitimate)\n",
    "remaining['prediction'] = np.where(ml_predictions == -1, 'FRAUD', 'LEGITIMATE')\n",
    "remaining['anomaly_score'] = anomaly_scores\n",
    "remaining['detection_stage'] = 'ML_ISOLATION_FOREST'\n",
    "\n",
    "# Add hard rule predictions back\n",
    "rule_safe['prediction'] = 'LEGITIMATE'\n",
    "rule_safe['anomaly_score'] = 0.0  # Not applicable for rule-based\n",
    "rule_safe['detection_stage'] = 'RULE_BASED'\n",
    "\n",
    "# Combine all predictions\n",
    "all_predictions = pd.concat([rule_safe, remaining], ignore_index=False).sort_index()\n",
    "\n",
    "print(f\"‚úÖ Predictions complete!\")\n",
    "print(f\"\\nüìä Prediction Distribution:\")\n",
    "print(all_predictions['prediction'].value_counts())\n",
    "print(f\"\\nüìä Detection Stage Distribution:\")\n",
    "print(all_predictions['detection_stage'].value_counts())\n",
    "\n",
    "# Show some example predictions\n",
    "print(f\"\\nüìã Example predictions:\")\n",
    "all_predictions[['phoneNumber', 'label', 'prediction', 'detection_stage', 'anomaly_score']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2841726e",
   "metadata": {},
   "source": [
    "## 9. üìà Calculate Performance Metrics\n",
    "\n",
    "Evaluate the model's performance using standard classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f267ec8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà TRAINING PERFORMANCE METRICS\n",
      "============================================================\n",
      "\n",
      "üéØ Overall Performance:\n",
      "  ‚Ä¢ Accuracy:  91.34%\n",
      "  ‚Ä¢ Precision: 81.32% (Low false positives)\n",
      "  ‚Ä¢ Recall:    76.90% (Catch fraudsters)\n",
      "  ‚Ä¢ F1-Score:  79.05%\n",
      "\n",
      "üìä Confusion Matrix:\n",
      "  ‚Ä¢ True Negatives (Legit ‚Üí Legit):  9,750\n",
      "  ‚Ä¢ False Positives (Legit ‚Üí Fraud): 488\n",
      "  ‚Ä¢ False Negatives (Fraud ‚Üí Legit): 638\n",
      "  ‚Ä¢ True Positives (Fraud ‚Üí Fraud):  2,124\n",
      "\n",
      "  ‚Ä¢ Overall False Positive Rate: 4.77%\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "y_true = (train_df['label'] == 'FRAUD').astype(int)\n",
    "y_pred = (all_predictions['prediction'] == 'FRAUD').astype(int)\n",
    "\n",
    "# Overall metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(\"üìà TRAINING PERFORMANCE METRICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nüéØ Overall Performance:\")\n",
    "print(f\"  ‚Ä¢ Accuracy:  {accuracy*100:.2f}%\")\n",
    "print(f\"  ‚Ä¢ Precision: {precision*100:.2f}% (Low false positives)\")\n",
    "print(f\"  ‚Ä¢ Recall:    {recall*100:.2f}% (Catch fraudsters)\")\n",
    "print(f\"  ‚Ä¢ F1-Score:  {f1*100:.2f}%\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(f\"\\nüìä Confusion Matrix:\")\n",
    "print(f\"  ‚Ä¢ True Negatives (Legit ‚Üí Legit):  {tn:,}\")\n",
    "print(f\"  ‚Ä¢ False Positives (Legit ‚Üí Fraud): {fp:,}\")\n",
    "print(f\"  ‚Ä¢ False Negatives (Fraud ‚Üí Legit): {fn:,}\")\n",
    "print(f\"  ‚Ä¢ True Positives (Fraud ‚Üí Fraud):  {tp:,}\")\n",
    "\n",
    "# False Positive Rate\n",
    "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "print(f\"\\n  ‚Ä¢ Overall False Positive Rate: {fpr*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e405d8ae",
   "metadata": {},
   "source": [
    "## 10. üõ°Ô∏è Critical Metric: Delivery Partner FPR\n",
    "\n",
    "Verify that the hard rule achieves **zero false positives** for delivery partners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fffcc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ°Ô∏è CRITICAL METRIC: Delivery Partner FPR\n",
      "============================================================\n",
      "Total Delivery Partners: 2554\n",
      "Incorrectly Flagged as Fraud: 0\n",
      "False Positive Rate: 0.0000%\n",
      "\n",
      "‚úÖ PERFECT! Zero false positives on delivery partners!\n",
      "   Hard rule is working correctly!\n",
      "\n",
      "üìä Delivery Partner Predictions:\n",
      "userType          label       prediction  detection_stage\n",
      "DELIVERY_PARTNER  LEGITIMATE  LEGITIMATE  RULE_BASED         2554\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check Delivery Partner False Positive Rate (CRITICAL METRIC)\n",
    "delivery_partners = train_df[\n",
    "    (train_df['callFrequency'] > 50) & \n",
    "    (train_df['avgCallDistance'] < 10) &\n",
    "    (train_df['label'] == 'LEGITIMATE')\n",
    "]\n",
    "\n",
    "print(\"üõ°Ô∏è CRITICAL METRIC: Delivery Partner FPR\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total Delivery Partners: {len(delivery_partners)}\")\n",
    "\n",
    "if len(delivery_partners) > 0:\n",
    "    delivery_predictions = all_predictions.loc[delivery_partners.index]\n",
    "    delivery_fp = (delivery_predictions['prediction'] == 'FRAUD').sum()\n",
    "    delivery_fpr = delivery_fp / len(delivery_partners)\n",
    "    \n",
    "    print(f\"Incorrectly Flagged as Fraud: {delivery_fp}\")\n",
    "    print(f\"False Positive Rate: {delivery_fpr*100:.4f}%\")\n",
    "    \n",
    "    if delivery_fpr == 0:\n",
    "        print(f\"\\n‚úÖ PERFECT! Zero false positives on delivery partners!\")\n",
    "        print(f\"   Hard rule is working correctly!\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è WARNING: {delivery_fp} delivery partners misclassified!\")\n",
    "        print(f\"   This should be 0! Check hard rule implementation.\")\n",
    "        \n",
    "    # Show delivery partner predictions\n",
    "    print(f\"\\nüìä Delivery Partner Predictions:\")\n",
    "    print(delivery_predictions[['userType', 'label', 'prediction', 'detection_stage']].value_counts())\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è No delivery partners found in training set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6399e72b",
   "metadata": {},
   "source": [
    "## 11. üìä Performance by User Type\n",
    "\n",
    "Analyze model performance for each user profile type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0200eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä PERFORMANCE BY USER TYPE\n",
      "============================================================\n",
      "  ‚úÖ BUSINESS_USER                 : 100.00% (3000/3000)\n",
      "  ‚ö†Ô∏è DELIVERY_PARTNER              : 91.97% (2759/3000)\n",
      "  ‚úÖ DIGITAL_ARREST_BOT            : 98.27% (1474/1500)\n",
      "  ‚ö†Ô∏è LOW_VOLUME_SCAMMER            : 29.39% (77/262)\n",
      "  ‚úÖ REGULAR_USER                  : 95.45% (3818/4000)\n",
      "  ‚ö†Ô∏è TRADITIONAL_SCAMMER           : 57.30% (573/1000)\n",
      "  ‚ö†Ô∏è TRAVELING_PROFESSIONAL        : 72.69% (173/238)\n",
      "\n",
      "üìã Summary Table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User Type</th>\n",
       "      <th>Samples</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BUSINESS_USER</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DELIVERY_PARTNER</td>\n",
       "      <td>3000</td>\n",
       "      <td>2759</td>\n",
       "      <td>91.97%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DIGITAL_ARREST_BOT</td>\n",
       "      <td>1500</td>\n",
       "      <td>1474</td>\n",
       "      <td>98.27%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LOW_VOLUME_SCAMMER</td>\n",
       "      <td>262</td>\n",
       "      <td>77</td>\n",
       "      <td>29.39%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REGULAR_USER</td>\n",
       "      <td>4000</td>\n",
       "      <td>3818</td>\n",
       "      <td>95.45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRADITIONAL_SCAMMER</td>\n",
       "      <td>1000</td>\n",
       "      <td>573</td>\n",
       "      <td>57.30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TRAVELING_PROFESSIONAL</td>\n",
       "      <td>238</td>\n",
       "      <td>173</td>\n",
       "      <td>72.69%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                User Type  Samples  Correct Accuracy\n",
       "0           BUSINESS_USER     3000     3000  100.00%\n",
       "1        DELIVERY_PARTNER     3000     2759   91.97%\n",
       "2      DIGITAL_ARREST_BOT     1500     1474   98.27%\n",
       "3      LOW_VOLUME_SCAMMER      262       77   29.39%\n",
       "4            REGULAR_USER     4000     3818   95.45%\n",
       "5     TRADITIONAL_SCAMMER     1000      573   57.30%\n",
       "6  TRAVELING_PROFESSIONAL      238      173   72.69%"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance by user type\n",
    "print(\"üìä PERFORMANCE BY USER TYPE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "user_types = train_df['userType'].unique()\n",
    "results = []\n",
    "\n",
    "for user_type in sorted(user_types):\n",
    "    mask = train_df['userType'] == user_type\n",
    "    subset_true = y_true[mask]\n",
    "    subset_pred = y_pred[mask]\n",
    "    \n",
    "    if len(subset_true) > 0:\n",
    "        acc = accuracy_score(subset_true, subset_pred)\n",
    "        n_samples = len(subset_true)\n",
    "        n_correct = (subset_true == subset_pred).sum()\n",
    "        \n",
    "        results.append({\n",
    "            'User Type': user_type,\n",
    "            'Samples': n_samples,\n",
    "            'Correct': n_correct,\n",
    "            'Accuracy': f\"{acc*100:.2f}%\"\n",
    "        })\n",
    "        \n",
    "        icon = '‚úÖ' if acc >= 0.95 else '‚ö†Ô∏è'\n",
    "        print(f\"  {icon} {user_type:30s}: {acc*100:5.2f}% ({n_correct}/{n_samples})\")\n",
    "\n",
    "# Create summary DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nüìã Summary Table:\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6645d4",
   "metadata": {},
   "source": [
    "## 12. üíæ Save Trained Model\n",
    "\n",
    "Save the model, scaler, and configuration for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73a65299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saving model...\n",
      "============================================================\n",
      "‚úì Saved: models/isolation_forest.pkl\n",
      "‚úì Saved: models/scaler.pkl\n",
      "‚úì Saved: models/config.json\n",
      "\n",
      "‚úÖ Model saved successfully!\n",
      "\n",
      "üí° Next steps:\n",
      "  1. Run 'python evaluate_model.py' to test on holdout data\n",
      "  2. Run 'python predict.py' for real-time predictions\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create models directory\n",
    "model_dir = 'models'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "print(\"üíæ Saving model...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save Isolation Forest\n",
    "joblib.dump(isolation_forest, f'{model_dir}/isolation_forest.pkl')\n",
    "print(f\"‚úì Saved: {model_dir}/isolation_forest.pkl\")\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, f'{model_dir}/scaler.pkl')\n",
    "print(f\"‚úì Saved: {model_dir}/scaler.pkl\")\n",
    "\n",
    "# Save configuration and statistics\n",
    "config = {\n",
    "    'feature_columns': feature_columns,\n",
    "    'n_estimators': n_estimators,\n",
    "    'contamination': contamination,\n",
    "    'max_samples': max_samples,\n",
    "    'random_state': random_state,\n",
    "    'training_stats': {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'total_samples': len(train_df),\n",
    "        'legitimate_samples': int((train_df['label'] == 'LEGITIMATE').sum()),\n",
    "        'fraud_samples': int((train_df['label'] == 'FRAUD').sum()),\n",
    "        'rule_based_protected': len(rule_safe),\n",
    "        'ml_evaluated': len(remaining),\n",
    "        'metrics': {\n",
    "            'accuracy': float(accuracy),\n",
    "            'precision': float(precision),\n",
    "            'recall': float(recall),\n",
    "            'f1_score': float(f1),\n",
    "            'true_positives': int(tp),\n",
    "            'true_negatives': int(tn),\n",
    "            'false_positives': int(fp),\n",
    "            'false_negatives': int(fn),\n",
    "            'delivery_partner_fpr': float(delivery_fpr) if 'delivery_fpr' in locals() else 0.0\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(f'{model_dir}/config.json', 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "print(f\"‚úì Saved: {model_dir}/config.json\")\n",
    "\n",
    "print(f\"\\n‚úÖ Model saved successfully!\")\n",
    "print(f\"\\nüí° Next steps:\")\n",
    "print(f\"  1. Run 'python evaluate_model.py' to test on holdout data\")\n",
    "print(f\"  2. Run 'python predict.py' for real-time predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e3ad13",
   "metadata": {},
   "source": [
    "## üéâ Training Complete!\n",
    "\n",
    "### Summary\n",
    "\n",
    "You've successfully trained a hybrid fraud detection model with:\n",
    "- **Stage 1**: Hard rule filter for delivery partners\n",
    "- **Stage 2**: Isolation Forest ML for anomaly detection\n",
    "\n",
    "### Key Variables Available\n",
    "\n",
    "You can now debug and explore these variables:\n",
    "- `train_df` - Original training data\n",
    "- `rule_safe` - Records protected by hard rule\n",
    "- `remaining` - Records evaluated by ML\n",
    "- `X_train` - Feature matrix (unscaled)\n",
    "- `X_train_scaled` - Feature matrix (scaled)\n",
    "- `scaler` - StandardScaler object\n",
    "- `isolation_forest` - Trained model\n",
    "- `all_predictions` - All predictions (rule + ML)\n",
    "- `y_true`, `y_pred` - True and predicted labels\n",
    "\n",
    "### Debugging Tips\n",
    "\n",
    "1. **Check specific predictions**: `all_predictions[all_predictions['phoneNumber'] == '+91XXXXXXXXXX']`\n",
    "2. **Find misclassifications**: `train_df[(y_true != y_pred)]`\n",
    "3. **Inspect anomaly scores**: `remaining[['phoneNumber', 'anomaly_score', 'prediction']].sort_values('anomaly_score')`\n",
    "4. **Test hard rule**: Modify the threshold and re-run cells 3-4\n",
    "5. **Tune model**: Change `n_estimators`, `contamination` in cell 6 and re-run from there\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Run all cells: `Kernel > Restart & Run All`\n",
    "- Test on new data: Load test dataset and use `isolation_forest.predict()`\n",
    "- Deploy: Use the saved models in `models/` directory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentinelx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
